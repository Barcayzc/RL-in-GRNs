{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_pbn_env.py\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import gym_PBN\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Paths to the prepared data\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# DATA_DIR          = Path('/Users/yzc/Desktop/Spring2025/CSCI1470/Final_Project/RL-in-GRNs/data_prepared')\n",
    "DATA_DIR         = Path('./data_prepared')\n",
    "TRAIN_STATES_PATH = DATA_DIR / \"train_states.npy\"\n",
    "LOGIC_PATH       = DATA_DIR / \"logic_func_data_safe.pkl\"\n",
    "GENE_NAMES_PATH  = DATA_DIR / \"gene_names_safe.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb99e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Load node names & logic functions\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "with open(GENE_NAMES_PATH, \"r\") as f:\n",
    "    node_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "with open(LOGIC_PATH, \"rb\") as f:\n",
    "    logic_map = pickle.load(f)\n",
    "\n",
    "logic_funcs     = [logic_map[name] for name in node_names]\n",
    "logic_func_data = (node_names, logic_funcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Decide the target domain\n",
    "#    Here: we’ll treat “all‐off” of some subset of genes as ‘success’. \n",
    "#    can replace this with whatever tuple(s) we need.\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#    For example, say we want genes 0,1,2 all = 0 in the target:\n",
    "target_nodes        = [0, 1, 2]                 # indices into node_names\n",
    "target_node_values  = ((0, 0, 0),)              # a tuple‐of‐tuples\n",
    "undesired_node_values = tuple()                 # no “wrong” attractors\n",
    "horizon             = 20                        # max steps\n",
    "\n",
    "goal_config = {\n",
    "    \"target_nodes\":         target_nodes,\n",
    "    \"target_node_values\":   target_node_values,\n",
    "    \"undesired_node_values\":undesired_node_values,\n",
    "    \"intervene_on\":         list(range(len(node_names))),  # all nodes are flippable\n",
    "    \"horizon\":              horizon,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0160d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/grn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Instantiate the **base** PBN environment\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "env = gym.make(\n",
    "        \"gym-PBN/PBN-v0\",\n",
    "        logic_func_data=(node_names, logic_funcs),\n",
    "        goal_config={\"all_attractors\": [], \"target\": set()},\n",
    "        reward_config={\n",
    "            \"successful_reward\":   5,\n",
    "            \"wrong_attractor_cost\":2,\n",
    "            \"action_cost\":         1\n",
    "        },\n",
    ")\n",
    "\n",
    "# set per-episode step-limit (the env calls it `horizon`)\n",
    "env.horizon = 20          # or whatever value we want\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9912fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset obs: [ True  True  True  True False  True False  True  True False  True  True\n",
      "  True  True False False False  True  True  True  True  True False  True\n",
      " False  True False  True  True False False  True False  True False  True\n",
      "  True  True  True  True False False  True False  True  True False False\n",
      " False False  True False  True False False False  True False False False\n",
      " False False  True False False False  True False  True False  True False\n",
      "  True  True  True False False False False False False False False  True\n",
      "  True False  True False  True  True False  True False  True False False\n",
      "  True False  True False] info: {'observation_idx': 1216827158475929188165224607050}\n",
      " step  0: action= 90, reward=-1.0, done=False\n",
      " step  1: action=100, reward=-1.0, done=False\n",
      " step  2: action= 41, reward=-1.0, done=False\n",
      " step  3: action=  0, reward= 0.0, done=False\n",
      " step  4: action= 70, reward=-1.0, done=False\n",
      "\n",
      "Obs space: MultiBinary(100)\n",
      "Act space: Discrete(101)\n",
      "Horizon  : 20\n",
      "Rewards  : {'success': 5, 'wrong': 2, 'cost': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/grn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:249: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Override reset‐pool to use train states\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "env.train_states = np.load(TRAIN_STATES_PATH)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 6) Smoke test: reset & take a few random steps\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "obs, info = env.reset(seed=0)\n",
    "print(\"Reset obs:\", obs, \"info:\", info)\n",
    "\n",
    "for t in range(5):\n",
    "    a = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(a)\n",
    "    print(f\" step {t:2d}: action={a:3d}, reward={reward:4.1f}, done={terminated or truncated}\")\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "print(\"\\nObs space:\", env.observation_space)\n",
    "print(\"Act space:\", env.action_space)\n",
    "print(\"Horizon  :\", env.horizon)\n",
    "print(\"Rewards  :\", {\n",
    "    \"success\" : env.successful_reward,\n",
    "    \"wrong\"   : env.wrong_attractor_cost,\n",
    "    \"cost\"    : env.action_cost\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
