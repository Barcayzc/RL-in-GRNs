{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405c4649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_api': 'blas', 'internal_api': 'openblas', 'num_threads': 1, 'prefix': 'libopenblas', 'filepath': '/opt/anaconda3/envs/grn/lib/libopenblas.0.dylib', 'version': '0.3.29', 'threading_layer': 'openmp', 'architecture': 'VORTEX'}, {'user_api': 'openmp', 'internal_api': 'openmp', 'num_threads': 1, 'prefix': 'libomp', 'filepath': '/opt/anaconda3/envs/grn/lib/libomp.dylib', 'version': None}, {'user_api': 'scipy', 'internal_api': 'scipy_mmio', 'num_threads': 0, 'prefix': '_fmm_core', 'filepath': '/opt/anaconda3/envs/grn/lib/python3.10/site-packages/scipy/io/_fast_matrix_market/_fmm_core.cpython-310-darwin.so', 'version': <function _fmm_version at 0x129d22a70>}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for v in (\"OMP_NUM_THREADS\",\"OPENBLAS_NUM_THREADS\",\"MKL_NUM_THREADS\",\n",
    "          \"VECLIB_MAXIMUM_THREADS\",\"NUMEXPR_MAX_THREADS\"):\n",
    "    os.environ[v] = \"1\"\n",
    "os.environ[\"OBJC_DISABLE_INITIALIZE_FORK_SAFETY\"] = \"YES\"\n",
    "\n",
    "from threadpoolctl import threadpool_info\n",
    "print(threadpool_info())  # every backend should list num_threads=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a135a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib, json, pandas as pd, itertools, warnings, tqdm, math, pickle\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import anndata\n",
    "from pathlib import Path\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "DATA_ROOT = Path(\n",
    "    \"/Users/yzc/Desktop/Spring2025/CSCI1470/Final Project/RL-in-GRNs/data/GSE132188_RAW\"\n",
    ")\n",
    "RUN1_DIR  = DATA_ROOT / \"mm10\"          # use replicate-1 for PoC\n",
    "OUT_DIR   = Path(\"./data_prepared\")      # everything save will live here\n",
    "OUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861e8bb",
   "metadata": {},
   "source": [
    "**1. Load 10× matrix → AnnData**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7053469e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 11183 × 27998\n",
      "    var: 'gene_ids'\n"
     ]
    }
   ],
   "source": [
    "# 1_load_10x.py\n",
    "adata = sc.read_10x_mtx(RUN1_DIR, gex_only=False)  # sparse AnnData\n",
    "adata.var_names_make_unique()\n",
    "print(adata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26aa34",
   "metadata": {},
   "source": [
    "**2. QC & normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca7b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wz/_2x6lz2x437d29bql459532c0000gn/T/ipykernel_2264/3389961315.py:6: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var['mt'] = adata.var_names.str.upper().str.startswith('MT-')\n",
      "/opt/anaconda3/envs/grn/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py:169: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 11122 × 27998\n",
      "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt'\n",
      "    var: 'gene_ids', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'mt'\n",
      "    uns: 'log1p'\n"
     ]
    }
   ],
   "source": [
    "# 2_qc_normalise.py\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "# 2.1 Identify mitochondrial genes (human: \"MT-\"; mouse: \"mt-\")\n",
    "adata.var['mt'] = adata.var_names.str.upper().str.startswith('MT-')\n",
    "\n",
    "# 2.2 Compute QC metrics, including percent mitochondrial counts\n",
    "sc.pp.calculate_qc_metrics(\n",
    "    adata,\n",
    "    qc_vars=['mt'],       # uses our 'mt' column to compute pct_counts_mt\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# 2.3 Filter cells\n",
    "#    - keep cells with > 500 detected genes\n",
    "#    - drop cells with > 10% mitochondrial reads\n",
    "adata = adata[adata.obs.n_genes_by_counts > 500, :]\n",
    "adata = adata[adata.obs.pct_counts_mt < 10, :]\n",
    "\n",
    "# 2.4 Library‐size normalisation and log1p transform\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "print(adata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0616947",
   "metadata": {},
   "source": [
    "**3. Choose gene panel (≤ 100 genes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55635767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/grn/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:61: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 100 genes\n"
     ]
    }
   ],
   "source": [
    "# 3_select_genes.py\n",
    "TARGET_N_GENES = 100\n",
    "\n",
    "sc.pp.highly_variable_genes(\n",
    "    adata, n_top_genes=TARGET_N_GENES, flavor=\"seurat_v3\", subset=True\n",
    ")\n",
    "selected_genes = adata.var_names.tolist()       # keep for later\n",
    "print(\"Selected\", len(selected_genes), \"genes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230f55c",
   "metadata": {},
   "source": [
    "**4. Binarize expression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c572d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary matrix: (11122, 100) dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "# 4_binarise.py\n",
    "from scipy import sparse\n",
    "\n",
    "# 4.1  Convert to a dense NumPy array\n",
    "if sparse.issparse(adata.X):\n",
    "    X_dense = adata.X.toarray()\n",
    "else:\n",
    "    X_dense = adata.X\n",
    "\n",
    "# 4.2  Define median‐split threshold function\n",
    "def median_split(vec: np.ndarray) -> float:\n",
    "    return np.median(vec)\n",
    "\n",
    "# 4.3  Compute per‐gene thresholds\n",
    "thresholds = np.apply_along_axis(median_split, 0, X_dense)\n",
    "\n",
    "# 4.4  Binarise: cells × genes → 0/1\n",
    "bin_X = (X_dense > thresholds).astype(np.uint8)\n",
    "print(\"Binary matrix:\", bin_X.shape, \"dtype:\", bin_X.dtype)\n",
    "\n",
    "# 4.5  Store in AnnData for convenience\n",
    "adata.layers[\"bin\"] = bin_X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0beb1c",
   "metadata": {},
   "source": [
    "**5. Infer Boolean rules → logic_func_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d371d6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built Boolean rules for 100 genes\n"
     ]
    }
   ],
   "source": [
    "# 5_infer_boolean_rules.py\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def find_topk_inputs(bin_mat, k=2):\n",
    "    \"\"\"Return list[list[int]]; each sub-list are indices of top-k correlated genes.\"\"\"\n",
    "    n_genes = bin_mat.shape[1]\n",
    "    inputs = []\n",
    "    for g in range(n_genes):\n",
    "        # compute |corr| with every other gene\n",
    "        corrs = [\n",
    "            (abs(pearsonr(bin_mat[:, g], bin_mat[:, j])[0]), j)\n",
    "            if g != j else (0.0, j)\n",
    "            for j in range(n_genes)\n",
    "        ]\n",
    "        topk = [j for _, j in sorted(corrs, reverse=True)[:k]]\n",
    "        inputs.append(topk)\n",
    "    return inputs\n",
    "\n",
    "top_inputs = find_topk_inputs(bin_X, k=2)\n",
    "\n",
    "def make_logic(expr_inputs, gene_idx):\n",
    "    # simple rule: gene g activates if ALL its two regulators are active\n",
    "    in1, in2 = expr_inputs\n",
    "    g1, g2 = selected_genes[in1], selected_genes[in2]\n",
    "    expr = f\"{g1} and {g2}\"\n",
    "    return [(expr, 0.8), (\"False\", 0.2)]   # 80 % ON when both inputs on\n",
    "\n",
    "logic_func_data = {\n",
    "    selected_genes[g]: make_logic(top_inputs[g], g)\n",
    "    for g in range(len(selected_genes))\n",
    "}\n",
    "print(\"Built Boolean rules for\", len(logic_func_data), \"genes\")\n",
    "\n",
    "# save\n",
    "with open(OUT_DIR / \"logic_func_data.pkl\", \"wb\") as fh:\n",
    "    pickle.dump(logic_func_data, fh)\n",
    "pd.Series(selected_genes).to_csv(OUT_DIR / \"gene_names.txt\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2725f",
   "metadata": {},
   "source": [
    "**6. Train / test split for initial states**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfeb20d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   (8897, 100)\n",
      "Test    (2225, 100)\n"
     ]
    }
   ],
   "source": [
    "# 6_split_states.py\n",
    "train_states, test_states = train_test_split(\n",
    "    bin_X, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "np.save(OUT_DIR / \"train_states.npy\", train_states)\n",
    "np.save(OUT_DIR / \"test_states.npy\",  test_states)\n",
    "print(\"Train  \", train_states.shape)\n",
    "print(\"Test   \", test_states.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d4696",
   "metadata": {},
   "source": [
    "**7. Summarise artifacts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d293e0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"n_cells\": 11122,\n",
      "  \"n_genes_total\": 100,\n",
      "  \"selected_genes\": 100,\n",
      "  \"train_cells\": 8897,\n",
      "  \"test_cells\": 2225\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 7_summary.py\n",
    "summary = {\n",
    "    \"n_cells\": int(adata.n_obs),\n",
    "    \"n_genes_total\": int(adata.n_vars),\n",
    "    \"selected_genes\": len(selected_genes),\n",
    "    \"train_cells\": len(train_states),\n",
    "    \"test_cells\": len(test_states),\n",
    "}\n",
    "print(json.dumps(summary, indent=2))\n",
    "with open(OUT_DIR / \"summary.json\", \"w\") as fh:\n",
    "    json.dump(summary, fh, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabfd3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data_prepared/logic_func_data_safe.pkl and data_prepared/gene_names_safe.txt\n"
     ]
    }
   ],
   "source": [
    "# fix_logic_names.py\n",
    "import pickle, json, numpy as np, re\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR   = Path(\"./data_prepared\")\n",
    "OLD_LOGIC  = DATA_DIR / \"logic_func_data.pkl\"\n",
    "OLD_NAMES  = DATA_DIR / \"gene_names.txt\"\n",
    "NEW_LOGIC  = DATA_DIR / \"logic_func_data_safe.pkl\"\n",
    "NEW_NAMES  = DATA_DIR / \"gene_names_safe.txt\"\n",
    "\n",
    "logic = pickle.loads(OLD_LOGIC.read_bytes())\n",
    "safe   = {}\n",
    "rename = {}                          # old → new\n",
    "\n",
    "for old in logic.keys():\n",
    "    # starts with letter? keep; else prefix with g_\n",
    "    new = old if re.match(r\"[A-Za-z_]\", old) else f\"g_{old}\"\n",
    "    rename[old] = new\n",
    "\n",
    "# ─ build new dict with safe keys + update expressions ─\n",
    "def replace_symbols(expr, renamer):\n",
    "    # token-wise replace; safe because symbols can only be [A-Z0-9_]\n",
    "    tokens = re.split(r\"(\\W)\", expr)   # keep delimiters\n",
    "    return \"\".join(renamer.get(tok, tok) for tok in tokens)\n",
    "\n",
    "for old_name, funclist in logic.items():\n",
    "    new_funclist = []\n",
    "    for expr, p in funclist:\n",
    "        new_expr = replace_symbols(expr, rename)\n",
    "        new_funclist.append((new_expr, p))\n",
    "    safe[rename[old_name]] = new_funclist\n",
    "\n",
    "# save artefacts\n",
    "pickle.dump(safe, NEW_LOGIC.open(\"wb\"))\n",
    "Path(NEW_NAMES).write_text(\"\\n\".join(safe.keys()))\n",
    "print(\"Saved\", NEW_LOGIC, \"and\", NEW_NAMES)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
